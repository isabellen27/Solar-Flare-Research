{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":9377450,"sourceType":"datasetVersion","datasetId":5688373},{"sourceId":9397033,"sourceType":"datasetVersion","datasetId":5703495},{"sourceId":9397035,"sourceType":"datasetVersion","datasetId":5703497},{"sourceId":9397311,"sourceType":"datasetVersion","datasetId":5703685},{"sourceId":9397318,"sourceType":"datasetVersion","datasetId":5703688},{"sourceId":9397363,"sourceType":"datasetVersion","datasetId":5703714},{"sourceId":9451786,"sourceType":"datasetVersion","datasetId":5745144},{"sourceId":115235,"sourceType":"modelInstanceVersion","modelInstanceId":96788,"modelId":120973},{"sourceId":165846,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":141107,"modelId":163716},{"sourceId":165848,"sourceType":"modelInstanceVersion","modelInstanceId":141109,"modelId":163719},{"sourceId":166214,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":141428,"modelId":164045},{"sourceId":172565,"sourceType":"modelInstanceVersion","modelInstanceId":146890,"modelId":169413},{"sourceId":176638,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":150423,"modelId":172905},{"sourceId":209080,"sourceType":"modelInstanceVersion","modelInstanceId":178258,"modelId":200555}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Isabelle Niu Solar Flare EfficientNet Model TPU Training\n\nNOTES:\n\nefficientnetv2b3:\n- better than v2b2\n\ndropout layer:\n- 0.5 \n\neven label dataset:\n- better for accuracy\n\nimage size:\n- changed to 300 x 300\n\nbatch size:\n- changed from 32 to 16 \n\nimage processing:\n- using random rotation with fill_mode = nearest\n\ntrainable layers:\n- training all three ending layers\n\nclass weights:\n- 1 vs 3\n\n\ntraining from epoch 4","metadata":{}},{"cell_type":"code","source":"!pip install astropy\n!pip install --upgrade pandas\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T02:47:16.081370Z","iopub.execute_input":"2024-11-21T02:47:16.081788Z","iopub.status.idle":"2024-11-21T02:47:37.306569Z","shell.execute_reply.started":"2024-11-21T02:47:16.081759Z","shell.execute_reply":"2024-11-21T02:47:37.305481Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow.keras as keras\nimport pandas as pd\nimport numpy as np\nfrom astropy.io import fits\nimport skimage\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.saving import register_keras_serializable","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-21T02:49:20.214158Z","iopub.execute_input":"2024-11-21T02:49:20.214508Z","iopub.status.idle":"2024-11-21T02:49:36.982092Z","shell.execute_reply.started":"2024-11-21T02:49:20.214475Z","shell.execute_reply":"2024-11-21T02:49:36.981292Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n\n# instantiate a distribution strategy\ntf.tpu.experimental.initialize_tpu_system(tpu)\ntpu_strategy = tf.distribute.TPUStrategy(tpu)","metadata":{"execution":{"iopub.status.busy":"2024-11-21T02:49:45.210288Z","iopub.execute_input":"2024-11-21T02:49:45.210519Z","iopub.status.idle":"2024-11-21T02:49:49.468310Z","shell.execute_reply.started":"2024-11-21T02:49:45.210488Z","shell.execute_reply":"2024-11-21T02:49:49.467592Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#ARs: 2284-2731\n#loading in the training data from the file\nmagnetogramTrainDf = pd.read_csv('/kaggle/input/datasetsmagnetogram/trainmagnetograms_even',dtype=str)\nmagnetogramTestDf = pd.read_csv('/kaggle/input/datasetsmagnetogram/testmagnetograms_even',dtype=str)\nmagnetogramValDf = pd.read_csv('/kaggle/input/datasetsmagnetogram/valmagnetograms_even',dtype=str)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-21T02:49:49.469878Z","iopub.execute_input":"2024-11-21T02:49:49.470156Z","iopub.status.idle":"2024-11-21T02:49:49.646730Z","shell.execute_reply.started":"2024-11-21T02:49:49.470127Z","shell.execute_reply":"2024-11-21T02:49:49.645974Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"imagesize = 300;\nbatchsize = 16;\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T02:49:49.647602Z","iopub.execute_input":"2024-11-21T02:49:49.647837Z","iopub.status.idle":"2024-11-21T02:49:49.651300Z","shell.execute_reply.started":"2024-11-21T02:49:49.647811Z","shell.execute_reply":"2024-11-21T02:49:49.650593Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Boucheron 2023\nclass FitsDataGen(keras.utils.Sequence):\n    # The input to the data generator will be the dataframe and which columns to use\n    def __init__(self, df, X_col, y_col,\n                 directory,\n                 batch_size,\n                 input_size=(imagesize, imagesize, 3),\n                 shuffle=True):\n        \n        self.df = df.copy() # dataframe\n        self.X_col = X_col # column for X data (filename)\n        self.y_col = y_col # column for y data (class label)\n        self.directory = directory # base directory for data\n        self.batch_size = batch_size # batch size\n        self.input_size = input_size # size expected by network (224,224,3) for VGG\n        self.shuffle = shuffle # whether to shuffle batches\n        \n        self.n = len(self.df) # number of data points\n        self.nclasses = df[y_col].nunique() # number of classes\n            \n    def on_epoch_end(self):\n        if self.shuffle:\n            self.df = self.df.sample(frac=1).reset_index(drop=True)\n    \n    def __get_input(self, path, directory, input_size):\n    \n        with fits.open(directory+path) as img: # read in fits image\n            img.verify('silentfix')\n            img = img[1].data\n            \n        img = np.expand_dims(img,axis=2) # copy single channel to three to create rgb dimensioned image\n        img = np.tile(img,(1,1,3))\n        \n        # scale to input_size (expected dimensions for input to network)\n        img = skimage.transform.resize(img, (input_size[0],input_size[1]), order=1, mode='reflect',\\\n                                       clip=True, preserve_range=True, anti_aliasing=True)\n        \n        # scale intensities to range [0,255] as expected by VGG preprocessing function\n        # can cheat a bit here and treat each channel the same since these are grayscale images\n        img = img + 5978.7 # -5978.7 is minimum of entire magnetogram dataset\n        img = img/(2*5978.7)*255 # +5978.7 is maximum of entire magnetogram dataset        \n        \n        img = keras.applications.efficientnet.preprocess_input(img) # preprocess according to VGG expectations\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_flip_up_down(img)\n        img = tf.keras.preprocessing.image.random_rotation(img, 10, fill_mode = \"nearest\")\n        return img\n    \n    def __get_output(self, label, num_classes):\n        return keras.utils.to_categorical(label, num_classes=num_classes)\n    \n    def __get_data(self, batches):\n        # Generates data containing batch_size samples\n\n        path_batch = batches[self.X_col]\n        \n        label_batch = batches[self.y_col]\n\n        X_batch = np.asarray([self.__get_input(x, self.directory, self.input_size) for x in path_batch])\n\n        y_batch = np.asarray([self.__get_output(y, self.nclasses) for y in label_batch])\n        \n        return X_batch, y_batch\n    \n    def __getitem__(self, index):\n        \n        batches = self.df[index * self.batch_size:(index + 1) * self.batch_size]\n        X, y = self.__get_data(batches)        \n        return X, y\n    \n    def __len__(self):\n        return self.n // self.batch_size","metadata":{"execution":{"iopub.status.busy":"2024-11-21T02:49:56.283046Z","iopub.execute_input":"2024-11-21T02:49:56.283744Z","iopub.status.idle":"2024-11-21T02:49:56.295577Z","shell.execute_reply.started":"2024-11-21T02:49:56.283705Z","shell.execute_reply":"2024-11-21T02:49:56.294881Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# custom metrics since these will not average batch to batch\nclass TNR(keras.metrics.Metric):\n    def __init__(self, name='TNR', **kwargs):\n        super(TNR, self).__init__(name=name, **kwargs)\n        self.TN = self.add_weight(name='TN', initializer='zeros')\n        self.FP = self.add_weight(name='FP', initializer='zeros')\n        self.TNR = self.add_weight(name='TNR', initializer='zeros')\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        y_true = keras.backend.argmax(y_true)\n        y_pred = keras.backend.argmax(y_pred)\n        neg_y_true = 1 - y_true\n        neg_y_pred = 1 - y_pred\n        fp = keras.backend.cast(keras.backend.sum(neg_y_true * y_pred),'float32')\n        tn = keras.backend.cast(keras.backend.sum(neg_y_true * neg_y_pred),'float32')\n        \n        self.TN.assign_add(tn)\n        self.FP.assign_add(fp)\n        \n        tnr = self.TN / (self.TN + self.FP + keras.backend.epsilon())\n        \n        self.TNR.assign(tnr)\n\n    def result(self):\n        return self.TNR\n\n    def reset_states(self):\n        self.TN.assign(0)\n        self.FP.assign(0)\n        self.TNR.assign(0)\n        \nclass TPR(keras.metrics.Metric):\n    def __init__(self, name='TPR', **kwargs):\n        super(TPR, self).__init__(name=name, **kwargs)\n        self.TP = self.add_weight(name='TP', initializer='zeros')\n        self.FN = self.add_weight(name='FN', initializer='zeros')\n        self.TPR = self.add_weight(name='TPR', initializer='zeros')\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        y_true = keras.backend.argmax(y_true)\n        y_pred = keras.backend.argmax(y_pred)\n        neg_y_pred = 1 - y_pred\n        fn = keras.backend.cast(keras.backend.sum(y_true * neg_y_pred),'float32')\n        tp = keras.backend.cast(keras.backend.sum(y_true * y_pred),'float32')\n        \n        self.TP.assign_add(tp)\n        self.FN.assign_add(fn)\n        \n        tpr = self.TP / (self.TP + self.FN + keras.backend.epsilon())\n        \n        self.TPR.assign(tpr)\n\n    def result(self):\n        return self.TPR\n\n    def reset_states(self):\n        self.TP.assign(0)\n        self.FN.assign(0)\n        self.TPR.assign(0)\n        \nclass TSS(keras.metrics.Metric):\n    def __init__(self, name='TSS', **kwargs):\n        super(TSS, self).__init__(name=name, **kwargs)\n        self.TP = self.add_weight(name='TP', initializer='zeros')\n        self.TN = self.add_weight(name='TN', initializer='zeros')\n        self.FP = self.add_weight(name='FP', initializer='zeros')\n        self.FN = self.add_weight(name='FN', initializer='zeros')\n        self.TSS = self.add_weight(name='TSS', initializer='zeros')\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        y_true = keras.backend.argmax(y_true)\n        y_pred = keras.backend.argmax(y_pred)\n        neg_y_true = 1 - y_true\n        neg_y_pred = 1 - y_pred\n        fp = keras.backend.cast(keras.backend.sum(neg_y_true * y_pred),'float32')\n        tn = keras.backend.cast(keras.backend.sum(neg_y_true * neg_y_pred),'float32')\n        fn = keras.backend.cast(keras.backend.sum(y_true * neg_y_pred),'float32')\n        tp = keras.backend.cast(keras.backend.sum(y_true * y_pred),'float32')\n        \n        self.TP.assign_add(tp)\n        self.TN.assign_add(tn)\n        self.FP.assign_add(fp)\n        self.FN.assign_add(fn)\n        \n        tnr = self.TN / (self.TN + self.FP + keras.backend.epsilon())\n        tpr = self.TP / (self.TP + self.FN + keras.backend.epsilon())\n        tss = tpr + tnr - 1\n       \n        self.TSS.assign(tss)\n\n    def result(self):\n        return keras.backend.cast(self.TSS, 'float32')\n\n    def reset_states(self):\n        self.TP.assign(0)\n        self.TN.assign(0)\n        self.FP.assign(0)\n        self.FN.assign(0)\n        self.TSS.assign(0)\n        \nclass HSS(keras.metrics.Metric):\n    def __init__(self, name='HSS', **kwargs):\n        super(HSS, self).__init__(name=name, **kwargs)\n        self.TP = self.add_weight(name='TP', initializer='zeros')\n        self.TN = self.add_weight(name='TN', initializer='zeros')\n        self.FP = self.add_weight(name='FP', initializer='zeros')\n        self.FN = self.add_weight(name='FN', initializer='zeros')\n        self.HSS = self.add_weight(name='HSS', initializer='zeros')\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        y_true = keras.backend.argmax(y_true)\n        y_pred = keras.backend.argmax(y_pred)\n        neg_y_true = 1 - y_true\n        neg_y_pred = 1 - y_pred\n        fp = keras.backend.cast(keras.backend.sum(neg_y_true * y_pred),'float32')\n        tn = keras.backend.cast(keras.backend.sum(neg_y_true * neg_y_pred),'float32')\n        fn = keras.backend.cast(keras.backend.sum(y_true * neg_y_pred),'float32')\n        tp = keras.backend.cast(keras.backend.sum(y_true * y_pred),'float32')\n        \n        self.TP.assign_add(tp)\n        self.TN.assign_add(tn)\n        self.FP.assign_add(fp)\n        self.FN.assign_add(fn)\n        \n        hss = 2*(self.TP*self.TN-self.FN*self.FP)/((self.TP+self.FN)*(self.FN+self.TN)+(self.TP+self.FP)*(self.FP+self.TN))\n       \n        self.HSS.assign(hss)\n\n    def result(self):\n        return self.HSS\n\n    def reset_states(self):\n        self.TP.assign(0)\n        self.TN.assign(0)\n        self.FP.assign(0)\n        self.FN.assign(0)\n        self.HSS.assign(0)\n        \nclass TN(keras.metrics.Metric):\n    def __init__(self, name='TN', **kwargs):\n        super(TN, self).__init__(name=name, **kwargs)\n        self.TN = self.add_weight(name='TN', initializer='zeros')\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        y_true = keras.backend.argmax(y_true)\n        y_pred = keras.backend.argmax(y_pred)\n        neg_y_true = 1 - y_true\n        neg_y_pred = 1 - y_pred\n        tn = keras.backend.cast(keras.backend.sum(neg_y_true * neg_y_pred),'float32')\n\n        self.TN.assign_add(tn)\n\n    def result(self):\n        return self.TN\n\n    def reset_states(self):\n        self.TN.assign(0)\n        \nclass TP(keras.metrics.Metric):\n    def __init__(self, name='TP', **kwargs):\n        super(TP, self).__init__(name=name, **kwargs)\n        self.TP = self.add_weight(name='FP', initializer='zeros')\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        y_true = keras.backend.argmax(y_true)\n        y_pred = keras.backend.argmax(y_pred)\n        tp = keras.backend.cast(keras.backend.sum(y_true * y_pred),'float32')\n\n        self.TP.assign_add(tp)\n\n    def result(self):\n        return self.TP\n\n    def reset_states(self):\n        self.TP.assign(0)\n        \nclass FN(keras.metrics.Metric):\n    def __init__(self, name='FN', **kwargs):\n        super(FN, self).__init__(name=name, **kwargs)\n        self.FN = self.add_weight(name='FN', initializer='zeros')\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        y_true = keras.backend.argmax(y_true)\n        y_pred = keras.backend.argmax(y_pred)\n        neg_y_pred = 1 - y_pred\n        fn = keras.backend.cast(keras.backend.sum(y_true * neg_y_pred),'float32')\n\n        self.FN.assign_add(fn)\n\n    def result(self):\n        return self.FN\n\n    def reset_states(self):\n        self.FN.assign(0)\n        \nclass FP(keras.metrics.Metric):\n    def __init__(self, name='FP', **kwargs):\n        super(FP, self).__init__(name=name, **kwargs)\n        self.FP = self.add_weight(name='FP', initializer='zeros')\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        y_true = keras.backend.argmax(y_true)\n        y_pred = keras.backend.argmax(y_pred)\n        neg_y_true = 1 - y_true\n        fp = keras.backend.cast(keras.backend.sum(neg_y_true * y_pred),'float32')\n\n        self.FP.assign_add(fp)\n\n    def result(self):\n        return self.FP\n\n    def reset_states(self):\n        self.FP.assign(0)\n\n@register_keras_serializable()\nclass F1Score(tf.keras.metrics.Metric):\n    def __init__(self, name='f1_score', **kwargs):\n        super(F1Score, self).__init__(name=name, **kwargs)\n        self.precision = tf.keras.metrics.Precision()\n        self.recall = tf.keras.metrics.Recall()\n    \n    def update_state(self, y_true, y_pred, sample_weight=None):\n        self.precision.update_state(y_true, y_pred, sample_weight)\n        self.recall.update_state(y_true, y_pred, sample_weight)\n    \n    def result(self):\n        precision = self.precision.result()\n        recall = self.recall.result()\n        return 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n    \n    def reset_states(self):\n        self.precision.reset_states()\n        self.recall.reset_states()","metadata":{"execution":{"iopub.status.busy":"2024-11-21T02:49:59.260005Z","iopub.execute_input":"2024-11-21T02:49:59.260834Z","iopub.status.idle":"2024-11-21T02:49:59.294091Z","shell.execute_reply.started":"2024-11-21T02:49:59.260795Z","shell.execute_reply":"2024-11-21T02:49:59.293377Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_generator = FitsDataGen(magnetogramTrainDf, X_col='filename', y_col='class',\\\n                                  directory='/kaggle/input/solar-flare-medium-dataset/Lat60_Lon60_Nans0/',\\\n                                  batch_size=batchsize, input_size=(imagesize, imagesize, 3), shuffle=True)\ntest_generator = FitsDataGen(magnetogramTestDf, X_col='filename', y_col='class',\\\n                                  directory='/kaggle/input/solar-flare-medium-dataset/Lat60_Lon60_Nans0/',\\\n                                  batch_size=batchsize, input_size=(imagesize, imagesize, 3), shuffle=True)\nval_generator = FitsDataGen(magnetogramValDf, X_col='filename', y_col='class',\\\n                                  directory='/kaggle/input/solar-flare-medium-dataset/Lat60_Lon60_Nans0/',\\\n                                  batch_size=batchsize, input_size=(imagesize, imagesize, 3), shuffle=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-21T02:50:06.158948Z","iopub.execute_input":"2024-11-21T02:50:06.159704Z","iopub.status.idle":"2024-11-21T02:50:06.170209Z","shell.execute_reply.started":"2024-11-21T02:50:06.159669Z","shell.execute_reply":"2024-11-21T02:50:06.169324Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#calculating the weights for each class in training set\nclass_weights = {0:1., 1: 1.5}","metadata":{"execution":{"iopub.status.busy":"2024-11-21T02:50:08.436589Z","iopub.execute_input":"2024-11-21T02:50:08.436938Z","iopub.status.idle":"2024-11-21T02:50:08.449207Z","shell.execute_reply.started":"2024-11-21T02:50:08.436907Z","shell.execute_reply":"2024-11-21T02:50:08.448481Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with tpu_strategy.scope():\n    results_dir = \"png\"\n    filepath = 'models/'+results_dir+'/model.{epoch:02d}_{val_TSS:.2f}.hdf5.keras'\n    checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_TSS', verbose=1, save_best_only=False, mode='max')\n    callbacks_list = [checkpoint]\n\n    step_size_train = int(np.ceil(train_generator.n/train_generator.batch_size))\n    step_size_val = int(np.ceil(val_generator.n/val_generator.batch_size))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-21T02:50:09.852912Z","iopub.execute_input":"2024-11-21T02:50:09.853427Z","iopub.status.idle":"2024-11-21T02:50:09.858756Z","shell.execute_reply.started":"2024-11-21T02:50:09.853393Z","shell.execute_reply":"2024-11-21T02:50:09.858045Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#creating a new model\nwith tpu_strategy.scope():\n    model = keras.applications.EfficientNetV2B3(\n    include_top=False, #automatically removes the last layers (pool + dropout + dense)\n    weights=\"imagenet\",\n    input_shape=(imagesize, imagesize, 3)\n    )\n\n    new_output = model.output # take the output as currently defined\n    new_output = keras.layers.GlobalAveragePooling2D()(new_output)\n    new_output = keras.layers.Dropout(0.5)(new_output)  \n    \n    new_output = keras.layers.Dense(2,activation='softmax')(new_output)\n    model = keras.models.Model(inputs=model.input,outputs=new_output) \n    adam_opt = keras.optimizers.Adam(learning_rate=0.001)\n    model.compile(loss='categorical_crossentropy', optimizer=adam_opt,\\\n               metrics=[TNR(), TPR(), TSS(), \"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2024-11-13T05:08:10.364947Z","iopub.execute_input":"2024-11-13T05:08:10.365928Z","iopub.status.idle":"2024-11-13T05:08:18.591410Z","shell.execute_reply.started":"2024-11-13T05:08:10.365886Z","shell.execute_reply":"2024-11-13T05:08:18.590407Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#running an existing model\nwith tpu_strategy.scope():\n    model = tf.keras.models.load_model(\n        \"/kaggle/input/efficientnetv2b3_epochs4-6_11.5_300x300/keras/default/1/models/png/model.01_0.47.hdf5.keras\",\n        custom_objects={'TNR': TNR(), 'TPR': TPR(), 'TSS': TSS(), 'F1Score' : F1Score()})\n    adam_opt = keras.optimizers.Adam(learning_rate=0.001)\n    model.compile(loss='categorical_crossentropy', optimizer=adam_opt,\\\n               metrics=[TNR(), TPR(), TSS(), \"accuracy\", F1Score()])","metadata":{"execution":{"iopub.status.busy":"2024-11-21T02:51:35.706707Z","iopub.execute_input":"2024-11-21T02:51:35.707095Z","iopub.status.idle":"2024-11-21T02:51:52.989426Z","shell.execute_reply.started":"2024-11-21T02:51:35.707062Z","shell.execute_reply":"2024-11-21T02:51:52.988338Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with tpu_strategy.scope(): \n    history = model.fit(train_generator, steps_per_epoch=step_size_train, epochs=3, verbose=1,\\\n                     callbacks=callbacks_list, validation_data=val_generator, validation_steps=step_size_val,\\\n                     validation_freq=1, class_weight=class_weights)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T02:51:56.772914Z","iopub.execute_input":"2024-11-21T02:51:56.773676Z"}},"outputs":[],"execution_count":null}]}
